// 1. 配置管理 - application.conf
spark {
  app-name = "DataWarehouseETL"
  master = "yarn"
  deploy-mode = "cluster"

  conf {
    "spark.sql.adaptive.enabled" = true
    "spark.sql.adaptive.coalescePartitions.enabled" = true
    "spark.sql.warehouse.dir" = "/user/hive/warehouse"
    "spark.sql.catalogImplementation" = "hive"
    "spark.executor.instances" = 10
    "spark.executor.cores" = 4
    "spark.executor.memory" = "4g"
    "spark.driver.memory" = "2g"
    "spark.sql.shuffle.partitions" = 400
  }
}

etl {
  date = "2024-01-01"
  layer = "all"  // all, dwd, dws
  table = "all"  // all, user, order, product, region
}