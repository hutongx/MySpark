status = warn
name = SparkDWPropertiesConfig

# Define appenders
appenders = console, file

# Console appender configuration
appender.console.type = Console
appender.console.name = STDOUT
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36}.%M(%L) - %msg%n

# File appender configuration (logs will be written to YARN container logs)
# You might configure a rolling file appender if needed, but YARN handles log aggregation.
appender.file.type = File
appender.file.name = FILE
appender.file.fileName = spark_dw_etl.log # Relative path, YARN manages actual location
appender.file.layout.type = PatternLayout
appender.file.layout.pattern = %d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36}.%M(%L) - %msg%n

# Root logger configuration
rootLogger.level = INFO # Or WARN, ERROR for production
rootLogger.appenderRefs = console, file # Change to just 'file' or preferred for production on YARN
rootLogger.appenderRef.console.ref = STDOUT
rootLogger.appenderRef.file.ref = FILE

# Configure logging levels for specific packages (optional)
logger.com.yourcompany.dw.level = DEBUG # More verbose for your application code during dev
logger.org.apache.spark.level = WARN
logger.org.eclipse.jetty.level = INFO
# ... other specific loggers